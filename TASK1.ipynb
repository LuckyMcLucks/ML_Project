{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f0dc4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/train_tfidf_features.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e87618d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    8507\n",
      "1    5240\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#split training df to train set and test set , 8:2 split\n",
    "\n",
    "train_df = df.iloc[:int(len(df)*0.8), :]\n",
    "test_df = df.iloc[int(len(df)*0.8):, :]\n",
    "\n",
    "X_train, y_train = train_df.drop(columns=[\"id\",\"label\"]),train_df[\"label\"]\n",
    "X_test, y_test = test_df.drop(columns=[\"id\",\"label\"]),test_df[\"label\"]\n",
    "\n",
    "\n",
    "counts = train_df[\"label\"].value_counts()\n",
    "print(counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44832866",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a class obj of Logistic Regression for used in Task 3\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self,seed=0,learning_rate = 0.01,batch_size = 100, epochs = 20,random_state = 0):\n",
    "        # X --> training data feaatures.\n",
    "        # y --> training data lable.   \n",
    "        # bs --> Batch Size.\n",
    "        # epochs --> Number of iterations.\n",
    "        # lr --> Learning rate. \n",
    "        # size-> number of training examples\n",
    "        # features-> number of features \n",
    "        self.size,self.features = 0,0\n",
    "        self.y_hat = 0.0\n",
    "        self.bs  = batch_size\n",
    "        self.lr = learning_rate\n",
    "        self.epochs =epochs\n",
    "        self.class_weights = None \n",
    "        self.random = random_state\n",
    "        \n",
    "        self.loss = 0\n",
    "\n",
    "    def sigmoid(self,z):\n",
    "        return 1.0/(1 + np.exp(-z))\n",
    "    \n",
    "    def loss_log(self,y,y_hat,sample_weights):\n",
    "        #included class weights\n",
    "        sample_weights = sample_weights[:, np.newaxis]\n",
    "        base_LOSS =  -np.mean(sample_weights *  (y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat)))\n",
    "        l1_penalty = self.Lambda * np.sum(np.abs(self.weights)) \n",
    "        return base_LOSS + l1_penalty\n",
    "    \n",
    "    def gradients(self,X, y, y_hat,sample_weights):\n",
    "        #included class weights\n",
    "        m = X.shape[0]\n",
    "        sample_weights = sample_weights[:, np.newaxis]\n",
    "        dw = 1/m * np.dot(X.T, sample_weights*(y_hat - y))+ self.Lambda * np.sign(self.weights) # dw + L1 regularization \n",
    "        db = np.mean(sample_weights*(y_hat - y))\n",
    "\n",
    "        return dw, db   \n",
    "    \n",
    "    def train(self,X,y,Lambda=1,class_weights=None,):\n",
    "        X = X.sample(frac=1, random_state=self.random).reset_index(drop=True)\n",
    "        y = y.sample(frac=1, random_state=self.random).reset_index(drop=True)\n",
    "        #Hyperparameter: \n",
    "        #Lambda --> L2 regularization \n",
    "        #class_weights --> sample weights\n",
    "        \n",
    "        self.Lambda = Lambda\n",
    "        self.class_weights = class_weights\n",
    "        #Added class weights to offset data class bias\n",
    "        if self.class_weights is not None:\n",
    "            sample_weights = np.vectorize(self.class_weights.get)(y.ravel()).reshape(-1, 1)\n",
    "\n",
    "        else:\n",
    "            sample_weights = np.ones_like(y)\n",
    "        self.size,features =X.shape\n",
    "        #Randomize initials bias and weights\n",
    "        self.weights =0\n",
    "        self.bias  =0\n",
    "        # Reshaping y.\n",
    "       \n",
    "        y = y.values.reshape(self.size, 1)\n",
    "        # Training loop.\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range((self.size-1)//self.bs + 1):\n",
    "                # Defining batches. SGD.\n",
    "                start_i = i*self.bs\n",
    "                end_i = start_i + self.bs\n",
    "                xb = X[start_i:end_i]\n",
    "                yb = y[start_i:end_i]\n",
    "                batch_weights = sample_weights[start_i:end_i]  \n",
    "                # Calculating hypothesis/prediction.\n",
    "                self.y_hat = self.sigmoid(np.dot(xb, self.weights) + self.bias)\n",
    "                #print(\"Probs:\", self.y_hat[:20])\n",
    "            \n",
    "                dw, db = self.gradients(xb, yb, self.y_hat, batch_weights)\n",
    "\n",
    "                # Updating the parameters.\n",
    "                self.weights -= self.lr*dw\n",
    "                self.bias -= self.lr*db\n",
    "\n",
    "            # Calculating/update loss log\n",
    "            self.loss =self.loss_log(y, self.sigmoid(np.dot(X, self.weights) + self.bias), sample_weights)\n",
    "\n",
    "           \n",
    "\n",
    "        # returning weights, bias and losses(List).\n",
    "\n",
    "        return self.weights, self.bias, self.loss\n",
    "    \n",
    "    def predict_proba(self,X):\n",
    "        #input X must be iterable \n",
    "        z = np.dot(X, self.weights) + self.bias\n",
    "        y_hat = self.sigmoid(z)\n",
    "        return np.round(y_hat)\n",
    "    \n",
    "    def predict(self,X):\n",
    "\n",
    "\n",
    "        probs = lg.predict(X_test)[:, 1]\n",
    "        ans = (probs >= 0.5).astype(int)\n",
    "        return ans\n",
    "    \n",
    "\n",
    "lg = LogisticRegression(batch_size=100, learning_rate=0.9, epochs=30)\n",
    "\n",
    "lg.train(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521cc0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = lg.predict(X_test)[:, 1]\n",
    "\n",
    "\n",
    "threshold = 0.63\n",
    "\n",
    "# Convert probabilities to class labels using the threshold\n",
    "ans = (probs >= threshold).astype(int)\n",
    "\n",
    "print(metrics.classification_report(y_test, ans))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7acf1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m metrics \n\u001b[0;32m      3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39mlg\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Wei Yang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Wei Yang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2671\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2563\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[0;32m   2564\u001b[0m \n\u001b[0;32m   2565\u001b[0m \u001b[38;5;124;03mRead more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2667\u001b[0m \u001b[38;5;124;03m<BLANKLINE>\u001b[39;00m\n\u001b[0;32m   2668\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2670\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[1;32m-> 2671\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2674\u001b[0m     labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\Wei Yang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:107\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    104\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    109\u001b[0m             type_true, type_pred\n\u001b[0;32m    110\u001b[0m         )\n\u001b[0;32m    111\u001b[0m     )\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    114\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "y_pred =lg.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "525489cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[43mlg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      4\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.67\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Convert probabilities to class labels using the threshold\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "probs = lg.predict(X_test)[:, 1]\n",
    "\n",
    "\n",
    "threshold = 0.67\n",
    "\n",
    "# Convert probabilities to class labels using the threshold\n",
    "ans = (probs >= threshold).astype(int)\n",
    "\n",
    "print(metrics.classification_report(y_test, ans))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cd8b66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.80      2126\n",
      "           1       0.69      0.52      0.59      1311\n",
      "\n",
      "    accuracy                           0.73      3437\n",
      "   macro avg       0.72      0.69      0.69      3437\n",
      "weighted avg       0.72      0.73      0.72      3437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV \n",
    "lg = LogisticRegressionCV(random_state=89)\n",
    "lg.fit(X_train,y_train)\n",
    "\n",
    "print(metrics.classification_report(y_test, lg.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5005fc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4296, 1)\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('data/test_tfidf_features.csv')\n",
    "test_data,id = test_df.drop(columns=[\"id\"]),test_df[\"id\"]\n",
    "probs = lg.predict(test_data)[:, 1]\n",
    "ans = (probs >= threshold).astype(int)\n",
    "\n",
    "\n",
    "final=id.to_frame()    \n",
    "print(final.shape)\n",
    "final[\"label\"] = ans\n",
    "final = final.rename(columns={\"id\":\"row ID\"})\n",
    "final.to_csv('Task1Output.csv',index=False )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
